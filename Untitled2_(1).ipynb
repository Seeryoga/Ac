{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Seeryoga/Ac/blob/main/Untitled2_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Na95_1xL4yoe",
        "outputId": "8c7ac2e4-073d-46bd-88f0-8cbd5c695657"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install streamlit -q"
      ],
      "metadata": {
        "id": "rRRk4lCc7ZcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysjy78ZjA29V",
        "outputId": "4b1bc201-9f4e-4531-d8b2-bfdd4b1f662d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import urllib.request\n",
        "import shutil\n",
        "import random\n",
        "import torch\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import streamlit as st\n",
        "from PIL import Image\n",
        "\n",
        "# Step 1: Extract the zip file\n",
        "def extract_dataset(url='https://clck.ru/3FkU9z', extract_path=\"/content/Dataset\"):\n",
        "\n",
        "    zip_file_path = 'agricultural_crops.zip'\n",
        "\n",
        "    print(\"Downloading dataset...\")\n",
        "    urllib.request.urlretrieve(url, zip_file_path)\n",
        "\n",
        "    print(\"Dataset downloaded successfully. Extracting...\")\n",
        "\n",
        "    # Извлечение zip-файла\n",
        "    os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n",
        "\n",
        "    print(\"Dataset extracted successfully.\")\n",
        "\n",
        "# Step 2: Create train-validation split\n",
        "def create_train_val_split(src_dir, dest_dir, val_ratio=0.2):\n",
        "    os.makedirs(os.path.join(dest_dir, 'train'), exist_ok=True)\n",
        "    os.makedirs(os.path.join(dest_dir, 'val'), exist_ok=True)\n",
        "\n",
        "    for class_name in os.listdir(src_dir):\n",
        "        if class_name.startswith('.'):\n",
        "            continue\n",
        "        class_dir = os.path.join(src_dir, class_name)\n",
        "        if os.path.isdir(class_dir):\n",
        "            files = [f for f in os.listdir(class_dir)\n",
        "                     if os.path.isfile(os.path.join(class_dir, f)) and not f.startswith('.')]\n",
        "            random.shuffle(files)\n",
        "            num_val = int(len(files) * val_ratio)\n",
        "\n",
        "            os.makedirs(os.path.join(dest_dir, 'train', class_name), exist_ok=True)\n",
        "            os.makedirs(os.path.join(dest_dir, 'val', class_name), exist_ok=True)\n",
        "\n",
        "            for i, file_name in enumerate(files):\n",
        "                if i < num_val:\n",
        "                    shutil.copy(os.path.join(class_dir, file_name), os.path.join(dest_dir, 'val', class_name))\n",
        "                else:\n",
        "                    shutil.copy(os.path.join(class_dir, file_name), os.path.join(dest_dir, 'train', class_name))\n",
        "\n",
        "# Step 3: Load and preprocess the data\n",
        "def load_data(data_dir='/content/Dataset_split'):\n",
        "    data_transforms = {\n",
        "        'train': transforms.Compose([\n",
        "            transforms.RandomResizedCrop(224),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ]),\n",
        "        'val': transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ]),\n",
        "    }\n",
        "\n",
        "    image_datasets = {x: datasets.ImageFolder(root=os.path.join(data_dir, x), transform=data_transforms[x])\n",
        "                      for x in ['train', 'val']}\n",
        "    dataloaders = {x: DataLoader(image_datasets[x], batch_size=32, shuffle=True, num_workers=4)\n",
        "                   for x in ['train', 'val']}\n",
        "    dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "    class_names = image_datasets['train'].classes\n",
        "\n",
        "    return dataloaders, dataset_sizes, class_names\n",
        "\n",
        "# Step 4: Load a pre-trained model\n",
        "def initialize_model(num_classes):\n",
        "    model_ft = models.resnet18(pretrained=True)\n",
        "    num_ftrs = model_ft.fc.in_features\n",
        "    model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "    return model_ft\n",
        "\n",
        "# Step 5: Train the model\n",
        "def train_model(model, dataloaders, dataset_sizes, num_epochs=15):\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer_ft = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
        "\n",
        "    best_model_wts = model.state_dict()\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                optimizer_ft.zero_grad()\n",
        "\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer_ft.step()\n",
        "\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            if phase == 'train':\n",
        "                exp_lr_scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = model.state_dict()\n",
        "\n",
        "        print()\n",
        "\n",
        "    print(f'Best val Acc: {best_acc:4f}')\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model\n",
        "\n",
        "# Step 6: Define a function to predict the class of an uploaded image\n",
        "def predict_image(image_path, model, class_names, device):\n",
        "    img = Image.open(image_path).convert('RGB')\n",
        "    preprocess = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    input_tensor = preprocess(img)\n",
        "    input_batch = input_tensor.unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(input_batch)\n",
        "\n",
        "    _, preds = torch.max(output, 1)\n",
        "    predicted_class = class_names[preds.item()]\n",
        "\n",
        "    return predicted_class\n",
        "\n",
        "# Main Streamlit App\n",
        "def main():\n",
        "    st.title(\"Классификация сельскохозяйственных культур\")\n",
        "\n",
        "    # Extract and prepare dataset\n",
        "    extract_dataset()\n",
        "    src_dir = os.path.join('/content/Dataset', 'Agricultural-crops')\n",
        "    dest_dir = '/content/Dataset_split'\n",
        "    create_train_val_split(src_dir, dest_dir)\n",
        "    dataloaders, dataset_sizes, class_names = load_data(data_dir=dest_dir)\n",
        "\n",
        "    # Initialize and train model\n",
        "    model = initialize_model(num_classes=len(class_names))\n",
        "    model = train_model(model, dataloaders, dataset_sizes, num_epochs=15)\n",
        "\n",
        "    # Save the trained model\n",
        "    torch.save(model.state_dict(), 'crop_classification_resnet.pth')\n",
        "\n",
        "    st.write(\"Модель обучена и сохранена.\")\n",
        "\n",
        "    uploaded_file = st.file_uploader(\"Загрузите изображение...\", type=[\"png\", \"jpg\", \"jpeg\", \"webp\"])\n",
        "    if uploaded_file is not None:\n",
        "        image_path = os.path.join('/tmp', uploaded_file.name)\n",
        "        with open(image_path, \"wb\") as f:\n",
        "            f.write(uploaded_file.getbuffer())\n",
        "\n",
        "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        model.load_state_dict(torch.load('crop_classification_resnet.pth', map_location=device))\n",
        "        model.eval()\n",
        "\n",
        "        predicted_class = predict_image(image_path, model, class_names, device)\n",
        "        st.image(image_path, caption='Загруженное изображение.', use_column_width=True)\n",
        "        st.write(f'Предсказанный класс: {predicted_class}')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}